# Modelo de IA utilizado
AI_MODEL = "gemini-2.5-flash"

# Tamaño máximo de texto por bloque para enviar a la IA
# (Evita errores por límite de tokens)
MAX_CHUNK_SIZE = 7000
